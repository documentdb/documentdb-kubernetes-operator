name: TEST - E2E Test with mongosh

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      node_count:
        description: 'Number of DocumentDB nodes'
        required: false
        default: '1'
      test_level:
        description: 'Test level to run'
        required: false
        default: 'full'
        type: choice
        options:
          - quick
          - integration
          - full
      image_tag:
        description: 'Optional: Use existing image tag instead of building locally'
        required: false
        type: string
  workflow_call:
    inputs:
      image_tag:
        description: 'Optional: Use existing image tag instead of building locally'
        required: false
        type: string
      node_count:
        description: 'Number of DocumentDB nodes'
        required: false
        default: '1'
        type: string
      test_level:
        description: 'Test level to run'
        required: false
        default: 'full'
        type: string

permissions:
  contents: read
  actions: read
  packages: read

env:
  CERT_MANAGER_NS: cert-manager
  OPERATOR_NS: documentdb-operator
  DB_NS: documentdb-e2e-test
  DB_NAME: documentdb-e2e
  DB_USERNAME: k8s_secret_user
  DB_PASSWORD: K8sSecret100
  DB_PORT: 10260

jobs:
  # Conditional build workflow - only run if image_tag is not provided or on pull_request
  build:
    name: Build Images and Charts
    if: ${{ (inputs.image_tag == '' || inputs.image_tag == null) || github.event_name == 'pull_request' }}
    uses: ./.github/workflows/test-build-and-package.yml
    with:
      version: '0.1.1'
    secrets: inherit

  e2e-test:
    name: Run E2E Tests
    runs-on: ${{ matrix.runner }}
    timeout-minutes: 60
    needs: build
    if: always() && (needs.build.result == 'success' || needs.build.result == 'skipped')
    
    strategy:
      matrix:
        include:
          - architecture: amd64
            runner: ubuntu-22.04
            test_scenario_name: "single-node"
            node_count: 1
            instances_per_node: 1
          - architecture: arm64
            runner: ubuntu-22.04-arm
            test_scenario_name: "single-node"
            node_count: 1
            instances_per_node: 1
    
    env:
      # Use built image tag on PR or when no external tag provided
      IMAGE_TAG: ${{ (github.event_name == 'pull_request' || inputs.image_tag == '' || inputs.image_tag == null) && needs.build.outputs.image_tag || inputs.image_tag }}
      CHART_VERSION: ${{ needs.build.outputs.chart_version || '0.1.0' }}
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Download artifacts
      if: ${{ (inputs.image_tag == '' || inputs.image_tag == null) || github.event_name == 'pull_request' }}
      uses: actions/download-artifact@v4
      with:
        pattern: 'build-*'
        path: ./artifacts

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Log test configuration
      run: |
        echo "## E2E Test Configuration" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        if [[ -n "${{ inputs.image_tag }}" ]]; then
          echo "- **Mode**: Using provided image tag" >> $GITHUB_STEP_SUMMARY
          echo "- **Image Tag**: \`${{ inputs.image_tag }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- **Source**: External (no local build)" >> $GITHUB_STEP_SUMMARY
        else
          echo "- **Mode**: Using locally built images" >> $GITHUB_STEP_SUMMARY
          echo "- **Image Tag**: \`${{ env.IMAGE_TAG }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- **Source**: Local build pipeline" >> $GITHUB_STEP_SUMMARY
        fi
        echo "- **Architecture**: \`${{ matrix.architecture }}\`" >> $GITHUB_STEP_SUMMARY

    - name: Setup test environment
      uses: ./.github/actions/setup-test-environment
      with:
        test-type: 'e2e'
        architecture: ${{ matrix.architecture }}
        runner: ${{ matrix.runner }}
        test-scenario-name: ${{ matrix.test_scenario_name }}
        node-count: '${{ matrix.node_count }}'
        instances-per-node: '${{ matrix.instances_per_node }}'
        cert-manager-namespace: ${{ env.CERT_MANAGER_NS }}
        operator-namespace: ${{ env.OPERATOR_NS }}
        db-namespace: ${{ env.DB_NS }}
        db-cluster-name: ${{ env.DB_NAME }}
        db-username: ${{ env.DB_USERNAME }}
        db-password: ${{ env.DB_PASSWORD }}
        db-port: ${{ env.DB_PORT }}
        image-tag: ${{ env.IMAGE_TAG }}
        chart-version: ${{ env.CHART_VERSION }}
        use-external-images: ${{ github.event_name != 'pull_request' && inputs.image_tag != '' && inputs.image_tag != null }}
        github-token: ${{ secrets.GITHUB_TOKEN }}
        repository-owner: ${{ github.repository_owner }}

    - name: Setup port forwarding for comprehensive tests
      uses: ./.github/actions/setup-port-forwarding
      with:
        namespace: ${{ env.DB_NS }}
        cluster-name: ${{ env.DB_NAME }}
        port: ${{ env.DB_PORT }}
        architecture: ${{ matrix.architecture }}
        test-type: 'comprehensive'

    - name: Execute comprehensive mongosh tests
      run: |
        echo "Running comprehensive mongosh validation tests on ${{ matrix.architecture }}..."
        
        # Run comprehensive tests with validation using external script
        if mongosh 127.0.0.1:$DB_PORT \
          -u $DB_USERNAME \
          -p $DB_PASSWORD \
          --authenticationMechanism SCRAM-SHA-256 \
          --tls \
          --tlsAllowInvalidCertificates \
          --file operator/src/scripts/test-scripts/comprehensive_mongosh_tests.js; then
          echo "✓ Comprehensive mongosh tests completed successfully on ${{ matrix.architecture }}"
        else
          echo "❌ Comprehensive mongosh tests failed on ${{ matrix.architecture }}"
          exit 1
        fi

    - name: Cleanup comprehensive test port forwarding
      if: always()
      run: |
        # Stop port-forward if it exists
        if [ -f /tmp/pf_pid ]; then
          PF_PID=$(cat /tmp/pf_pid)
          kill $PF_PID 2>/dev/null || true
          rm -f /tmp/pf_pid
        fi
        
        # Clean up output log
        rm -f /tmp/pf_output.log
        
        # Clean up output log
        rm -f /tmp/pf_output.log

    - name: Setup port forwarding for performance tests
      uses: ./.github/actions/setup-port-forwarding
      with:
        namespace: ${{ env.DB_NS }}
        cluster-name: ${{ env.DB_NAME }}
        port: ${{ env.DB_PORT }}
        architecture: ${{ matrix.architecture }}
        test-type: 'performance'

    - name: Execute performance tests
      run: |
        echo "Running performance validation tests on ${{ matrix.architecture }}..."
        
        # Run performance tests using external script
        if mongosh 127.0.0.1:$DB_PORT \
          -u $DB_USERNAME \
          -p $DB_PASSWORD \
          --authenticationMechanism SCRAM-SHA-256 \
          --tls \
          --tlsAllowInvalidCertificates \
          --file operator/src/scripts/test-scripts/performance_test.js; then
          echo "✓ Performance tests completed successfully on ${{ matrix.architecture }}"
        else
          echo "❌ Performance tests failed on ${{ matrix.architecture }}"
          exit 1
        fi

    - name: Cleanup performance testing
      if: always()
      run: |
        # Stop performance test port-forward
        if [ -f /tmp/perf_pf_pid ]; then
          PF_PID=$(cat /tmp/perf_pf_pid)
          kill $PF_PID 2>/dev/null || true
          rm -f /tmp/perf_pf_pid
        fi
        
        # Clean up output log
        rm -f /tmp/perf_pf_output.log
        
        # Clean up output log
        rm -f /tmp/perf_pf_output.log

    - name: Verify DocumentDB Status and Connection String
      run: |
        echo "Verifying DocumentDB status fields on ${{ matrix.architecture }}..."
        
        # Get the DocumentDB resource status
        DB_STATUS=$(kubectl get documentdb $DB_NAME -n $DB_NS -o jsonpath='{.status.status}')
        CONNECTION_STRING=$(kubectl get documentdb $DB_NAME -n $DB_NS -o jsonpath='{.status.connectionString}')
        
        echo "DocumentDB Status: $DB_STATUS"
        echo "Connection String: ${CONNECTION_STRING:0:50}..." # Print first 50 chars only
        
        # Verify status is "Cluster in healthy state"
        if [[ "$DB_STATUS" == "Cluster in healthy state" ]]; then
          echo "✓ DocumentDB status is healthy"
        else
          echo "❌ DocumentDB status is not healthy: $DB_STATUS"
          kubectl get documentdb $DB_NAME -n $DB_NS -o yaml
          exit 1
        fi
        
        # Verify connection string is not empty
        if [[ -n "$CONNECTION_STRING" ]]; then
          echo "✓ Connection string is populated"
        else
          echo "❌ Connection string is empty"
          kubectl get documentdb $DB_NAME -n $DB_NS -o yaml
          exit 1
        fi
        
        echo "✅ DocumentDB status validation passed"

    - name: Test cluster health and monitoring
      run: |
        echo "Testing cluster health and monitoring on ${{ matrix.architecture }}..."
        
        # Check DocumentDB resource status
        kubectl get documentdb $DB_NAME -n $DB_NS -o yaml
        
        # Check pod resources and health
        kubectl top pods -n $DB_NS --containers || echo "Metrics server not available"
        
        # Check logs for any errors
        kubectl logs -n $DB_NS -l cnpg.io/cluster=$DB_NAME --tail=50
        
        # Check events
        kubectl get events -n $DB_NS --sort-by='.lastTimestamp'

    - name: Verify mount options are set by PV controller
      run: |
        echo "Verifying PV mount options are set by the PV controller..."
        
        # Get the PVC and PV names from the existing cluster
        pvc_name=$(kubectl -n ${{ env.DB_NS }} get pvc -l cnpg.io/cluster=${{ env.DB_NAME }} -o jsonpath='{.items[0].metadata.name}')
        pv_name=$(kubectl -n ${{ env.DB_NS }} get pvc $pvc_name -o jsonpath='{.spec.volumeName}')
        
        echo "PVC name: $pvc_name"
        echo "PV name: $pv_name"
        
        if [ -z "$pv_name" ]; then
          echo "❌ Failed to find PV bound to PVC $pvc_name"
          exit 1
        fi
        
        # Get mount options from PV
        mount_options=$(kubectl get pv $pv_name -o jsonpath='{.spec.mountOptions}')
        echo "PV mount options: $mount_options"
        
        # Check for security mount options (nodev, nosuid, noexec)
        if echo "$mount_options" | grep -q "nodev" && \
           echo "$mount_options" | grep -q "nosuid" && \
           echo "$mount_options" | grep -q "noexec"; then
          echo "✓ PV mount options (nodev, nosuid, noexec) are set correctly"
        else
          echo "❌ PV mount options are missing. Expected nodev, nosuid, noexec"
          exit 1
        fi

    - name: Test PV reclaim policy default and explicit Delete
      shell: bash
      run: |
        echo "Testing PV reclaim policy - default (Retain) and explicit Delete..."
        
        # Test 1: Verify default policy is Retain on the existing cluster
        echo "=== Test 1: Verify default PV reclaim policy is Retain ==="
        
        # Get the PVC and PV names from the existing cluster
        pvc_name=$(kubectl -n ${{ env.DB_NS }} get pvc -l cnpg.io/cluster=${{ env.DB_NAME }} -o jsonpath='{.items[0].metadata.name}')
        pv_name=$(kubectl -n ${{ env.DB_NS }} get pvc $pvc_name -o jsonpath='{.spec.volumeName}')
        
        echo "PVC name: $pvc_name"
        echo "PV name: $pv_name"
        
        if [ -z "$pv_name" ]; then
          echo "❌ Failed to find PV bound to PVC $pvc_name"
          exit 1
        fi
        
        # Verify default PV reclaim policy is Retain
        current_policy=$(kubectl get pv $pv_name -o jsonpath='{.spec.persistentVolumeReclaimPolicy}')
        echo "Current PV reclaim policy: $current_policy"
        
        if [ "$current_policy" != "Retain" ]; then
          echo "❌ Expected default PV reclaim policy to be 'Retain', but got '$current_policy'"
          exit 1
        fi
        echo "✓ Default PV reclaim policy is correctly set to Retain"
        
        # Test 2: Change policy to Delete and verify PV is deleted with cluster
        echo ""
        echo "=== Test 2: Change policy to Delete and verify PV cleanup ==="
        
        # Patch the existing DocumentDB to set persistentVolumeReclaimPolicy to Delete
        echo "Patching DocumentDB to set persistentVolumeReclaimPolicy to Delete..."
        kubectl -n ${{ env.DB_NS }} patch documentdb ${{ env.DB_NAME }} --type=merge \
          -p '{"spec":{"resource":{"storage":{"persistentVolumeReclaimPolicy":"Delete"}}}}'
        
        # Wait for PV controller to update the PV reclaim policy
        echo "Waiting for PV reclaim policy to be updated to Delete..."
        MAX_RETRIES=30
        SLEEP_INTERVAL=5
        ITER=0
        while [ $ITER -lt $MAX_RETRIES ]; do
          new_policy=$(kubectl get pv $pv_name -o jsonpath='{.spec.persistentVolumeReclaimPolicy}')
          if [ "$new_policy" == "Delete" ]; then
            echo "✓ PV reclaim policy updated to Delete"
            break
          else
            echo "PV reclaim policy is still '$new_policy'. Waiting..."
            sleep $SLEEP_INTERVAL
          fi
          ((++ITER))
        done
        
        if [ "$new_policy" != "Delete" ]; then
          echo "❌ PV reclaim policy was not updated to Delete within expected time"
          exit 1
        fi
        
        # Delete the DocumentDB cluster
        echo "Deleting DocumentDB cluster to test PV cleanup with Delete policy..."
        kubectl -n ${{ env.DB_NS }} delete documentdb ${{ env.DB_NAME }} --wait=false
        
        # Wait for DocumentDB to be deleted
        echo "Waiting for DocumentDB to be deleted..."
        MAX_RETRIES=30
        SLEEP_INTERVAL=10
        ITER=0
        while [ $ITER -lt $MAX_RETRIES ]; do
          db_exists=$(kubectl -n ${{ env.DB_NS }} get documentdb ${{ env.DB_NAME }} --ignore-not-found)
          if [ -z "$db_exists" ]; then
            echo "✓ DocumentDB deleted successfully."
            break
          else
            echo "DocumentDB still exists. Waiting..."
            sleep $SLEEP_INTERVAL
          fi
          ((++ITER))
        done
        
        # Verify no PVsRetained warning event was emitted (since policy is Delete)
        events=$(kubectl -n ${{ env.DB_NS }} get events --field-selector reason=PVsRetained,involvedObject.name=${{ env.DB_NAME }} --ignore-not-found -o jsonpath='{.items}')
        if [ -z "$events" ] || [ "$events" == "[]" ]; then
          echo "✓ No PVsRetained warning event emitted (expected for Delete policy)"
        else
          echo "⚠️ Unexpected PVsRetained event found for Delete policy cluster"
        fi
        
        # Wait a bit for PV to be deleted (the storage class handles actual deletion)
        echo "Waiting for PV to be deleted..."
        sleep 30
        
        # Verify PV was deleted (because reclaim policy is Delete)
        pv_exists=$(kubectl get pv $pv_name --ignore-not-found 2>/dev/null)
        if [ -z "$pv_exists" ]; then
          echo "✓ PV $pv_name was deleted as expected (Delete policy)"
        else
          pv_status=$(kubectl get pv $pv_name -o jsonpath='{.status.phase}')
          echo "⚠️ PV $pv_name still exists with status: $pv_status"
          echo "Note: PV deletion depends on the storage provisioner. The reclaim policy was correctly set to Delete."
        fi
        
        echo ""
        echo "✓ PV reclaim policy test completed successfully"

    - name: Collect comprehensive logs on failure
      if: failure()
      uses: ./.github/actions/collect-logs
      with:
        architecture: ${{ matrix.architecture }}
        operator-namespace: ${{ env.OPERATOR_NS }}
        db-namespace: ${{ env.DB_NS }}
        db-name: ${{ env.DB_NAME }}

    - name: Test completion summary
      if: always()
      run: |
        echo "## E2E Test Summary for ${{ matrix.architecture }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "- **Architecture**: ${{ matrix.architecture }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Runner**: ${{ matrix.runner }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Test Scenario**: ${{ matrix.test_scenario_name }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Node Count**: ${{ matrix.node_count }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Image Tag**: ${{ env.IMAGE_TAG }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Chart Version**: ${{ env.CHART_VERSION }}" >> $GITHUB_STEP_SUMMARY
        if [[ -n "${{ inputs.image_tag }}" ]]; then
          echo "- **Using External Images**: true" >> $GITHUB_STEP_SUMMARY
        else
          echo "- **Using External Images**: false" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [[ "${{ job.status }}" == "success" ]]; then
          echo "- **Status**: ✅ PASSED" >> $GITHUB_STEP_SUMMARY
        else
          echo "- **Status**: ❌ FAILED" >> $GITHUB_STEP_SUMMARY
        fi

  test-summary:
    name: E2E Test Summary
    runs-on: ubuntu-latest
    if: always()
    needs: [build, e2e-test]
    steps:
    - name: Generate overall test summary
      run: |
        echo "## E2E Test Results Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### Test Configuration:" >> $GITHUB_STEP_SUMMARY
        echo "- **Build Step**: ${{ inputs.image_tag && 'Skipped (using external images)' || 'Executed' }}" >> $GITHUB_STEP_SUMMARY
        echo "- **External Images**: ${{ inputs.image_tag && 'true' || 'false' }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Image Tag**: ${{ inputs.image_tag || 'Built from source' }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### Parallel Architecture Testing:" >> $GITHUB_STEP_SUMMARY
        echo "- **AMD64**: Tested in parallel on ubuntu-latest" >> $GITHUB_STEP_SUMMARY
        echo "- **ARM64**: Tested in parallel on ubuntu-22.04-arm" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "Both architectures run simultaneously for faster feedback!" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### Job Results:" >> $GITHUB_STEP_SUMMARY
        echo "- **Build**: ${{ needs.build.result }}" >> $GITHUB_STEP_SUMMARY
        echo "- **E2E Tests**: ${{ needs.e2e-test.result }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Overall status
        if [[ "${{ needs.e2e-test.result }}" == "success" ]]; then
          echo "### Overall Status: ✅ ALL TESTS PASSED" >> $GITHUB_STEP_SUMMARY
          echo "Both AMD64 and ARM64 architectures tested successfully in parallel!" >> $GITHUB_STEP_SUMMARY
        else
          echo "### Overall Status: ❌ SOME TESTS FAILED" >> $GITHUB_STEP_SUMMARY
          echo "Check individual job results above for details." >> $GITHUB_STEP_SUMMARY
        fi
